{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating YOLOv3 in DeepStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov3 config and weights files ... \n",
      "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
      "yolov3.weights      100%[===================>] 236.52M  12.4MB/s    in 21s     \n"
     ]
    }
   ],
   "source": [
    "! ../model/prebuild.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/opt/nvidia/deepstream/deepstream-5.0/yolov3/source_code/nvdsinfer_custom_impl_Yolo'\n",
      "make: Nothing to be done for 'all'.\n",
      "make: Leaving directory '/opt/nvidia/deepstream/deepstream-5.0/yolov3/source_code/nvdsinfer_custom_impl_Yolo'\n"
     ]
    }
   ],
   "source": [
    "!make -C ../source_code/nvdsinfer_custom_impl_Yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries \n",
    "import sys\n",
    "sys.path.append('../source_code')\n",
    "import gi\n",
    "import time\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, Gst, GLib\n",
    "from common.bus_call import bus_call\n",
    "import pyds\n",
    "\n",
    "# Defining the Class Labels\n",
    "PGIE_CLASS_ID_PERSON = 0\n",
    "PGIE_CLASS_ID_BICYCLE = 1\n",
    "PGIE_CLASS_ID_CAR = 2\n",
    "PGIE_CLASS_ID_BUS = 5\n",
    "PGIE_CLASS_ID_TRAIN = 6\n",
    "PGIE_CLASS_ID_TRUCK = 7\n",
    "PGIE_CLASS_ID_BACKPACK = 24\n",
    "PGIE_CLASS_ID_SURFBOARD = 37\n",
    "\n",
    "\n",
    "# Defining the input output video file \n",
    "INPUT_VIDEO_NAME  = '../videos/sample_720p.h264'\n",
    "OUTPUT_VIDEO_NAME = \"../videos/out.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Element or Print Error and any other detail\n",
    "def make_elm_or_print_err(factoryname, name, printedname, detail=\"\"):\n",
    "  print(\"Creating\", printedname)\n",
    "  elm = Gst.ElementFactory.make(factoryname, name)\n",
    "  if not elm:\n",
    "     sys.stderr.write(\"Unable to create \" + printedname + \" \\n\")\n",
    "  if detail:\n",
    "     sys.stderr.write(detail)\n",
    "  return elm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise GStreamer and Create an Empty Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Pipeline \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Standard GStreamer initialization\n",
    "Gst.init(None)\n",
    "\n",
    "\n",
    "# Create Gstreamer elements\n",
    "# Create Pipeline element that will form a connection of other elements\n",
    "print(\"Creating Pipeline \\n \")\n",
    "pipeline = Gst.Pipeline()\n",
    "\n",
    "if not pipeline:\n",
    "    sys.stderr.write(\" Unable to create Pipeline \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Elements that are required for our pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Source\n",
      "Creating h264 parse\n",
      "Creating Nvv4l2 Decoder\n",
      "Creating NvStreamMux\n",
      "Creating pgie\n",
      "Creating nvvidconv\n",
      "Creating nvosd\n",
      "Creating Queue\n",
      "Creating nvvidconv2\n",
      "Creating Encoder\n",
      "Creating Code Parser\n",
      "Creating Container\n",
      "Creating Sink\n"
     ]
    }
   ],
   "source": [
    "# Creating elements required for the pipeline\n",
    "# Source element for reading from file\n",
    "source = make_elm_or_print_err(\"filesrc\", \"file-source\",\"Source\")\n",
    "# Parse the data since the input is an elementary .h264 stream\n",
    "h264parser = make_elm_or_print_err(\"h264parse\", \"h264-parser\",\"h264 parse\")\n",
    "# For hardware accelerated decoding of the stream\n",
    "decoder = make_elm_or_print_err(\"nvv4l2decoder\", \"nvv4l2-decoder\",\"Nvv4l2 Decoder\")\n",
    "# Form batches from one or more sources\n",
    "streammux = make_elm_or_print_err(\"nvstreammux\", \"Stream-muxer\",'NvStreamMux')\n",
    "# Run inference on the decoded stream, this property is set through a configuration file later\n",
    "pgie = make_elm_or_print_err(\"nvinfer\", \"primary-inference\" ,\"pgie\")\n",
    "# Convert output stream to formatted buffer accepted by Nvosd\n",
    "nvvidconv = make_elm_or_print_err(\"nvvideoconvert\", \"convertor\",\"nvvidconv\")\n",
    "# Draw on the buffer\n",
    "nvosd = make_elm_or_print_err(\"nvdsosd\", \"onscreendisplay\",\"nvosd\")\n",
    "# Encode and save the OSD output\n",
    "queue = make_elm_or_print_err(\"queue\", \"queue\", \"Queue\")\n",
    "# Convert output for saving\n",
    "nvvidconv2 = make_elm_or_print_err(\"nvvideoconvert\", \"convertor2\",\"nvvidconv2\")\n",
    "# Save as video file\n",
    "encoder = make_elm_or_print_err(\"avenc_mpeg4\", \"encoder\", \"Encoder\")\n",
    "# Parse output from encoder\n",
    "codeparser = make_elm_or_print_err(\"mpeg4videoparse\", \"mpeg4-parser\", 'Code Parser')\n",
    "# Create a container\n",
    "container = make_elm_or_print_err(\"qtmux\", \"qtmux\", \"Container\")\n",
    "# Create sink for string the output\n",
    "sink = make_elm_or_print_err(\"filesink\", \"filesink\", \"Sink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Properties in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing file ../videos/sample_720p.h264\n"
     ]
    }
   ],
   "source": [
    "# Set properties for elements\n",
    "print(\"Playing file %s\" %INPUT_VIDEO_NAME)\n",
    "# Set input file\n",
    "source.set_property('location', INPUT_VIDEO_NAME)\n",
    "# Set input height, width, and batch size\n",
    "streammux.set_property('width', 1920)\n",
    "streammux.set_property('height', 1080)\n",
    "streammux.set_property('batch-size', 1)\n",
    "# Set timer (in microseconds) to wait after the first buffer is available\n",
    "# to push the batch even if batch is never completely formed\n",
    "streammux.set_property('batched-push-timeout', 4000000)\n",
    "# Set configuration files for Nvinfer\n",
    "pgie.set_property('config-file-path', \"../configs/config_infer_primary_yoloV3.txt\")\n",
    "# Set encoder bitrate for output video\n",
    "encoder.set_property(\"bitrate\", 2000000)\n",
    "# Set output file location, disable sync and async\n",
    "sink.set_property(\"location\", OUTPUT_VIDEO_NAME)\n",
    "sink.set_property(\"sync\", 0)\n",
    "sink.set_property(\"async\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and Linking elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding elements to Pipeline \n",
      "\n",
      "Linking elements in the Pipeline \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and link all elements to the pipeline\n",
    "# Adding elements\n",
    "print(\"Adding elements to Pipeline \\n\")\n",
    "\n",
    "pipeline.add(source)\n",
    "pipeline.add(h264parser)\n",
    "pipeline.add(decoder)\n",
    "pipeline.add(streammux)\n",
    "pipeline.add(pgie)\n",
    "pipeline.add(nvvidconv)\n",
    "pipeline.add(nvosd)\n",
    "pipeline.add(queue)\n",
    "pipeline.add(nvvidconv2)\n",
    "pipeline.add(encoder)\n",
    "pipeline.add(codeparser)\n",
    "pipeline.add(container)\n",
    "pipeline.add(sink)\n",
    "\n",
    "# Linking elements\n",
    "# Order: source -> h264parser -> decoder -> streammux -> pgie ->\n",
    "# -> vidconv -> osd -> queue -> vidconv2 -> encoder -> parser ->\n",
    "# -> container -> sink\n",
    "\n",
    "print(\"Linking elements in the Pipeline \\n\")\n",
    "source.link(h264parser)\n",
    "h264parser.link(decoder)\n",
    "\n",
    "\n",
    "sinkpad = streammux.get_request_pad(\"sink_0\")\n",
    "if not sinkpad:\n",
    "    sys.stderr.write(\" Unable to get the sink pad of streammux \\n\")\n",
    "# Create source pad from Decoder   \n",
    "srcpad = decoder.get_static_pad(\"src\")\n",
    "if not srcpad:\n",
    "    sys.stderr.write(\" Unable to get source pad of decoder \\n\")\n",
    "    \n",
    "srcpad.link(sinkpad)\n",
    "streammux.link(pgie)\n",
    "pgie.link(nvvidconv)\n",
    "nvvidconv.link(nvosd)\n",
    "nvosd.link(queue)\n",
    "queue.link(nvvidconv2)\n",
    "nvvidconv2.link(encoder)\n",
    "encoder.link(codeparser)\n",
    "codeparser.link(container)\n",
    "container.link(sink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an event loop and feed GStreamer bus messages to it\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect (\"message\", bus_call, loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the Metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with metadata\n",
    "def osd_sink_pad_buffer_probe(pad,info,u_data):\n",
    "    \n",
    "    obj_counter = {\n",
    "        PGIE_CLASS_ID_PERSON:0,\n",
    "        PGIE_CLASS_ID_BICYCLE:0,\n",
    "        PGIE_CLASS_ID_CAR:0,\n",
    "        PGIE_CLASS_ID_BUS:0,\n",
    "        PGIE_CLASS_ID_TRAIN:0,\n",
    "        PGIE_CLASS_ID_TRUCK:0,\n",
    "        PGIE_CLASS_ID_BACKPACK:0,\n",
    "        PGIE_CLASS_ID_SURFBOARD:0\n",
    "    }\n",
    "    # Reset frame number and number of rectanges to zero\n",
    "    frame_number=0\n",
    "    num_rects=0\n",
    "    \n",
    "    gst_buffer = info.get_buffer()\n",
    "    if not gst_buffer:\n",
    "        print(\"Unable to get GstBuffer \")\n",
    "        return\n",
    "\n",
    "    # Retrieve metadata from gst_buffer\n",
    "    # Note: since we use the pyds shared object library,\n",
    "    # the input is the C address of gst_buffer\n",
    "    batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame = batch_meta.frame_meta_list\n",
    "    while l_frame is not None:\n",
    "        try:\n",
    "            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        # Get frame number, number of rectangles to draw and object metadata\n",
    "        frame_number=frame_meta.frame_num\n",
    "        num_rects = frame_meta.num_obj_meta\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        \n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            # Increment object class by 1 and set box border color to red\n",
    "            obj_counter[obj_meta.class_id] += 1\n",
    "            obj_meta.rect_params.border_color.set(0.0, 0.0, 1.0, 0.0)\n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        # Setting metadata display configuration\n",
    "        # Acquire display meta object\n",
    "        display_meta=pyds.nvds_acquire_display_meta_from_pool(batch_meta)\n",
    "        display_meta.num_labels = 1\n",
    "        py_nvosd_text_params = display_meta.text_params[0]\n",
    "        # Set display text to be shown on screen\n",
    "        # py_nvosd_text_params.display_text = \"Frame Number={} Number of Objects={} Vehicle_count={} Person_count={}\".format(frame_number, num_rects, obj_counter[PGIE_CLASS_ID_VEHICLE], obj_counter[PGIE_CLASS_ID_PERSON])\n",
    "        # Set where the string will appear\n",
    "        py_nvosd_text_params.x_offset = 10\n",
    "        py_nvosd_text_params.y_offset = 12\n",
    "        # Font, font colour and font size\n",
    "        py_nvosd_text_params.font_params.font_name = \"Serif\"\n",
    "        py_nvosd_text_params.font_params.font_size = 10\n",
    "        # Set color (We used white)\n",
    "        py_nvosd_text_params.font_params.font_color.set(1.0, 1.0, 1.0, 1.0)\n",
    "        # Set text background colour (We used black)\n",
    "        py_nvosd_text_params.set_bg_clr = 1\n",
    "        py_nvosd_text_params.text_bg_clr.set(0.0, 0.0, 0.0, 1.0)\n",
    "        # Print the display text in the console as well\n",
    "        #print(pyds.get_string(py_nvosd_text_params.display_text))\n",
    "        pyds.nvds_add_display_meta_to_frame(frame_meta, display_meta)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding probe to sinkpad of the OSD element\n",
    "osdsinkpad = nvosd.get_static_pad(\"sink\")\n",
    "if not osdsinkpad:\n",
    "    sys.stderr.write(\" Unable to get sink pad of nvosd \\n\")\n",
    "    \n",
    "osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, osd_sink_pad_buffer_probe, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline \n",
      "\n",
      "End-of-stream\n",
      "--- 25.884523630142212 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Start the pipeline\n",
    "print(\"Starting pipeline \\n\")\n",
    "start_time = time.time()\n",
    "pipeline.set_state(Gst.State.PLAYING)\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    pass\n",
    "# Cleanup\n",
    "pipeline.set_state(Gst.State.NULL)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video profile to be compatible with the Notebook\n",
    "!ffmpeg -loglevel panic -y -an -i ../videos/out.mp4 -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -level 3 ../videos/output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <video width=\"640\" height=\"480\" controls>\n",
       " <source src=\"../videos/output.mp4\"\n",
       " </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the Output\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    " <video width=\"640\" height=\"480\" controls>\n",
    " <source src=\"../videos/output.mp4\"\n",
    " </video>\n",
    "\"\"\".format())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
